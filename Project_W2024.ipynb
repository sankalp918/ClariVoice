{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "In this Project, you will bring together many of the tools and techniques that you have learned throughout this course into a final project. You can choose from many different paths to get to the solution. \n",
    "\n",
    "### Business scenario\n",
    "\n",
    "You work for a training organization that recently developed an introductory course about machine learning (ML). The course includes more than 40 videos that cover a broad range of ML topics. You have been asked to create an application that will students can use to quickly locate and view video content by searching for topics and key phrases.\n",
    "\n",
    "You have downloaded all of the videos to an Amazon Simple Storage Service (Amazon S3) bucket. Your assignment is to produce a dashboard that meets your supervisorâ€™s requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project steps\n",
    "\n",
    "To complete this project, you will follow these steps:\n",
    "\n",
    "1. [Viewing the video files](#1.-Viewing-the-video-files)\n",
    "2. [Transcribing the videos](#2.-Transcribing-the-videos)\n",
    "3. [Normalizing the text](#3.-Normalizing-the-text)\n",
    "4. [Extracting key phrases and topics](#4.-Extracting-key-phrases-and-topics)\n",
    "5. [Creating the dashboard](#5.-Creating-the-dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful information\n",
    "\n",
    "The following cell contains some information that might be useful as you complete this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = \"c56161a939430l3396553t1w744137092661-labbucket-rn642jaq01e9\"\n",
    "job_data_access_role = 'arn:aws:iam::744137092661:role/service-role/c56161a939430l3396553t1w7-ComprehendDataAccessRole-1P24MSS91ADHP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Viewing the video files\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source video files are located in the following shared Amazon Simple Storage Service (Amazon S3) bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-26 20:17:33  410925369 Mod01_Course Overview.mp4\n",
      "2021-04-26 20:10:02   39576695 Mod02_Intro.mp4\n",
      "2021-04-26 20:31:23  302994828 Mod02_Sect01.mp4\n",
      "2021-04-26 20:17:33  416563881 Mod02_Sect02.mp4\n",
      "2021-04-26 20:17:33  318685583 Mod02_Sect03.mp4\n",
      "2021-04-26 20:17:33  255877251 Mod02_Sect04.mp4\n",
      "2021-04-26 20:23:51   99988046 Mod02_Sect05.mp4\n",
      "2021-04-26 20:24:54   50700224 Mod02_WrapUp.mp4\n",
      "2021-04-26 20:26:27   60627667 Mod03_Intro.mp4\n",
      "2021-04-26 20:26:28  272229844 Mod03_Sect01.mp4\n",
      "2021-04-26 20:27:06  309127124 Mod03_Sect02_part1.mp4\n",
      "2021-04-26 20:27:06  195635527 Mod03_Sect02_part2.mp4\n",
      "2021-04-26 20:28:03  123924818 Mod03_Sect02_part3.mp4\n",
      "2021-04-26 20:31:28  171681915 Mod03_Sect03_part1.mp4\n",
      "2021-04-26 20:32:07  285200083 Mod03_Sect03_part2.mp4\n",
      "2021-04-26 20:33:17  105470345 Mod03_Sect03_part3.mp4\n",
      "2021-04-26 20:35:10  157185651 Mod03_Sect04_part1.mp4\n",
      "2021-04-26 20:36:27  187435635 Mod03_Sect04_part2.mp4\n",
      "2021-04-26 20:36:40  280720369 Mod03_Sect04_part3.mp4\n",
      "2021-04-26 20:40:01  443479313 Mod03_Sect05.mp4\n",
      "2021-04-26 20:40:08  234182186 Mod03_Sect06.mp4\n",
      "2021-04-26 20:40:33  207718047 Mod03_Sect07_part1.mp4\n",
      "2021-04-26 20:42:07  125592110 Mod03_Sect07_part2.mp4\n",
      "2021-04-26 20:45:10  508500301 Mod03_Sect07_part3.mp4\n",
      "2021-04-26 20:46:16  320126756 Mod03_Sect08.mp4\n",
      "2021-04-26 20:46:43   41839508 Mod03_WrapUp.mp4\n",
      "2021-04-26 20:46:55   34148489 Mod04_Intro.mp4\n",
      "2021-04-26 20:48:24   84959465 Mod04_Sect01.mp4\n",
      "2021-04-26 20:48:25  345182970 Mod04_Sect02_part1.mp4\n",
      "2021-04-26 20:51:34  218661651 Mod04_Sect02_part2.mp4\n",
      "2021-04-26 20:53:32  430140637 Mod04_Sect02_part3.mp4\n",
      "2021-04-26 20:56:03   22036605 Mod04_WrapUp.mp4\n",
      "2021-04-26 20:57:18   49187118 Mod05_Intro.mp4\n",
      "2021-04-26 20:58:19  245798071 Mod05_Sect01_ver2.mp4\n",
      "2021-04-26 20:58:50  233314835 Mod05_Sect02_part1_ver2.mp4\n",
      "2021-04-26 20:59:14  348545306 Mod05_Sect02_part2.mp4\n",
      "2021-04-26 20:59:17  239142711 Mod05_Sect03_part1.mp4\n",
      "2021-04-26 21:06:04  267533559 Mod05_Sect03_part2.mp4\n",
      "2021-04-26 21:06:06  212502220 Mod05_Sect03_part3.mp4\n",
      "2021-04-26 21:06:48  206317022 Mod05_Sect03_part4_ver2.mp4\n",
      "2021-04-26 21:06:48   60361230 Mod05_WrapUp_ver2.mp4\n",
      "2021-04-26 21:09:14   35397860 Mod06_Intro.mp4\n",
      "2021-04-26 21:09:24  845633599 Mod06_Sect01.mp4\n",
      "2021-04-26 21:10:47  326126684 Mod06_Sect02.mp4\n",
      "2021-04-26 21:12:26   19790740 Mod06_WrapUp.mp4\n",
      "2021-04-26 21:12:56  131249036 Mod07_Sect01.mp4\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transcribing the videos\n",
    " ([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to implement your solution to transcribe the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-07T16:35:48.982061Z",
     "start_time": "2024-04-07T16:34:53.794598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: transformers in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (4.39.3)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp311-cp311-win_amd64.whl (2454.8 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.17.2%2Bcu121-cp311-cp311-win_amd64.whl (5.7 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: nltk in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (3.7.4)\n",
      "Requirement already satisfied: bertopic in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: dash in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: dash-core-components in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: dash-html-components in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: click in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (2.6.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (69.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: hdbscan>=0.8.29 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from bertopic) (0.8.33)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from bertopic) (0.5.6)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from bertopic) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from bertopic) (1.4.1.post1)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from bertopic) (2.6.1)\n",
      "Requirement already satisfied: plotly>=4.7.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from bertopic) (5.20.0)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from dash) (3.0.2)\n",
      "Requirement already satisfied: Werkzeug<3.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from dash) (3.0.2)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from dash) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from dash) (6.11.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from dash) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from dash) (1.6.0)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (1.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: cython<3,>=0.27 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (0.29.37)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pandas>=1.1.5->bertopic) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from plotly>=4.7.0->bertopic) (8.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.4.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.59.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.5.12)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from importlib-metadata->dash) (3.18.1)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from retrying->dash) (1.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.42.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.2.2+cu121 torchaudio-2.2.2+cu121 torchvision-0.17.2+cu121\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.1/12.8 MB 907.3 kB/s eta 0:00:15\n",
      "      --------------------------------------- 0.2/12.8 MB 1.6 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.5/12.8 MB 2.9 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.0/12.8 MB 4.7 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.0/12.8 MB 4.1 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.6/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.6/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.2/12.8 MB 4.3 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.3/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.9/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.0/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.8/12.8 MB 6.4 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 6.7 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.1/12.8 MB 7.2 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 7.0/12.8 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.9/12.8 MB 8.4 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.8/12.8 MB 8.9 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 9.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 9.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.6/12.8 MB 10.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.4/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 12.5/12.8 MB 14.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.7/12.8 MB 15.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sandy\\pycharmprojects\\pythonproject\\.venv\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "\u001B[38;5;2m[+] Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites for the code to run\n",
    "!pip install transformers torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 nltk spacy bertopic dash dash-core-components dash-html-components\n",
    "\n",
    "# For converting video to audio ffmpeg is required to be installed\n",
    "#!apt-get install ffmpeg\n",
    "\n",
    "# Downloading en_core_web_sm model\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Downloading S3 bucket to sagemaker notebook\n",
    "#!aws s3 sync s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/ ."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:35:48.984971Z",
     "start_time": "2024-04-07T16:35:48.983075Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-07T16:53:17.703874Z",
     "start_time": "2024-04-07T16:36:30.268998Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:697: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription for Mod01_Course_Overview.mp4 saved to Mod01_Course_Overview_transcription.txt\n",
      "Transcription for Mod02_Intro.mp4 saved to Mod02_Intro_transcription.txt\n",
      "Transcription for Mod02_Sect01.mp4 saved to Mod02_Sect01_transcription.txt\n",
      "Transcription for Mod02_Sect02.mp4 saved to Mod02_Sect02_transcription.txt\n",
      "Transcription for Mod02_Sect03.mp4 saved to Mod02_Sect03_transcription.txt\n",
      "Transcription for Mod02_Sect04.mp4 saved to Mod02_Sect04_transcription.txt\n",
      "Transcription for Mod02_Sect05.mp4 saved to Mod02_Sect05_transcription.txt\n",
      "Transcription for Mod02_WrapUp.mp4 saved to Mod02_WrapUp_transcription.txt\n",
      "Transcription for Mod03_Intro.mp4 saved to Mod03_Intro_transcription.txt\n",
      "Transcription for Mod03_Sect01.mp4 saved to Mod03_Sect01_transcription.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\logging\\__init__.py\", line 1110, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\logging\\__init__.py\", line 953, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\logging\\__init__.py\", line 687, in format\n",
      "    record.message = record.getMessage()\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\logging\\__init__.py\", line 377, in getMessage\n",
      "    msg = msg % self.args\n",
      "          ~~~~^~~~~~~~~~~\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Sandy\\AppData\\Local\\Temp\\ipykernel_8752\\3077709642.py\", line 53, in <module>\n",
      "    transcription = transcribe_audio(audio_file_path, pipe)  # Transcribe audio\n",
      "  File \"C:\\Users\\Sandy\\AppData\\Local\\Temp\\ipykernel_8752\\3077709642.py\", line 14, in transcribe_audio\n",
      "    result = pipe(audio_file_path, generate_kwargs={\"language\": \"english\"})\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py\", line 285, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 1167, in __call__\n",
      "    logger.warning_once(\n",
      "  File \"C:\\Users\\Sandy\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\transformers\\utils\\logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\n",
      "Arguments: (<class 'UserWarning'>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription for Mod03_Sect02_part1.mp4 saved to Mod03_Sect02_part1_transcription.txt\n",
      "Transcription for Mod03_Sect02_part2.mp4 saved to Mod03_Sect02_part2_transcription.txt\n",
      "Transcription for Mod03_Sect02_part3.mp4 saved to Mod03_Sect02_part3_transcription.txt\n",
      "Transcription for Mod03_Sect03_part1.mp4 saved to Mod03_Sect03_part1_transcription.txt\n",
      "Transcription for Mod03_Sect03_part2.mp4 saved to Mod03_Sect03_part2_transcription.txt\n",
      "Transcription for Mod03_Sect03_part3.mp4 saved to Mod03_Sect03_part3_transcription.txt\n",
      "Transcription for Mod03_Sect04_part1.mp4 saved to Mod03_Sect04_part1_transcription.txt\n",
      "Transcription for Mod03_Sect04_part2.mp4 saved to Mod03_Sect04_part2_transcription.txt\n",
      "Transcription for Mod03_Sect04_part3.mp4 saved to Mod03_Sect04_part3_transcription.txt\n",
      "Transcription for Mod03_Sect05.mp4 saved to Mod03_Sect05_transcription.txt\n",
      "Transcription for Mod03_Sect06.mp4 saved to Mod03_Sect06_transcription.txt\n",
      "Transcription for Mod03_Sect07_part1.mp4 saved to Mod03_Sect07_part1_transcription.txt\n",
      "Transcription for Mod03_Sect07_part2.mp4 saved to Mod03_Sect07_part2_transcription.txt\n",
      "Transcription for Mod03_Sect07_part3.mp4 saved to Mod03_Sect07_part3_transcription.txt\n",
      "Transcription for Mod03_Sect08.mp4 saved to Mod03_Sect08_transcription.txt\n",
      "Transcription for Mod03_WrapUp.mp4 saved to Mod03_WrapUp_transcription.txt\n",
      "Transcription for Mod04_Intro.mp4 saved to Mod04_Intro_transcription.txt\n",
      "Transcription for Mod04_Sect01.mp4 saved to Mod04_Sect01_transcription.txt\n",
      "Transcription for Mod04_Sect02_part1.mp4 saved to Mod04_Sect02_part1_transcription.txt\n",
      "Transcription for Mod04_Sect02_part2.mp4 saved to Mod04_Sect02_part2_transcription.txt\n",
      "Transcription for Mod04_Sect02_part3.mp4 saved to Mod04_Sect02_part3_transcription.txt\n",
      "Transcription for Mod04_WrapUp.mp4 saved to Mod04_WrapUp_transcription.txt\n",
      "Transcription for Mod05_Intro.mp4 saved to Mod05_Intro_transcription.txt\n",
      "Transcription for Mod05_Sect01_ver2.mp4 saved to Mod05_Sect01_ver2_transcription.txt\n",
      "Transcription for Mod05_Sect02_part1_ver2.mp4 saved to Mod05_Sect02_part1_ver2_transcription.txt\n",
      "Transcription for Mod05_Sect02_part2.mp4 saved to Mod05_Sect02_part2_transcription.txt\n",
      "Transcription for Mod05_Sect03_part1.mp4 saved to Mod05_Sect03_part1_transcription.txt\n",
      "Transcription for Mod05_Sect03_part2.mp4 saved to Mod05_Sect03_part2_transcription.txt\n",
      "Transcription for Mod05_Sect03_part3.mp4 saved to Mod05_Sect03_part3_transcription.txt\n",
      "Transcription for Mod05_Sect03_part4_ver2.mp4 saved to Mod05_Sect03_part4_ver2_transcription.txt\n",
      "Transcription for Mod05_WrapUp_ver2.mp4 saved to Mod05_WrapUp_ver2_transcription.txt\n",
      "Transcription for Mod06_Intro.mp4 saved to Mod06_Intro_transcription.txt\n",
      "Transcription for Mod06_Sect01.mp4 saved to Mod06_Sect01_transcription.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription for Mod06_Sect02.mp4 saved to Mod06_Sect02_transcription.txt\n",
      "Transcription for Mod06_WrapUp.mp4 saved to Mod06_WrapUp_transcription.txt\n",
      "Transcription for Mod07_Sect01.mp4 saved to Mod07_Sect01_transcription.txt\n"
     ]
    }
   ],
   "source": [
    "# Write your answer/code here\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "# Function to extract audio from video\n",
    "def extract_audio(video_path, output_audio_path):\n",
    "    command = [\"ffmpeg\", \"-i\", video_path, \"-ab\", \"160k\", \"-ac\", \"1\", \"-ar\", \"16000\", \"-vn\", output_audio_path]\n",
    "    os.system(\" \".join(command))  # Execute ffmpeg command\n",
    "\n",
    "# Function to transcribe audio file\n",
    "def transcribe_audio(audio_file_path, pipe):\n",
    "    result = pipe(audio_file_path, generate_kwargs={\"language\": \"english\"})\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# Load pre-trained model and processor\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_id, torch_dtype=torch_dtype, use_safetensors=True)\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create pipeline for automatic speech recognition\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Get all video files in the current directory\n",
    "video_files = [f for f in os.listdir() if f.endswith('.mp4') or f.endswith('.avi')]\n",
    "\n",
    "# Convert each video to audio and transcribe it\n",
    "for video_file in video_files:\n",
    "    # Replace spaces in the filename with underscores\n",
    "    new_video_file = video_file.replace(' ', '_')\n",
    "    os.rename(video_file, new_video_file)\n",
    "    video_file = new_video_file\n",
    "    \n",
    "    audio_file_path = video_file.split('.')[0] + '.wav'  # Create audio file path\n",
    "    extract_audio(video_file, audio_file_path)  # Extract audio from video\n",
    "    transcription = transcribe_audio(audio_file_path, pipe)  # Transcribe audio\n",
    "    \n",
    "    # Save transcription to a text file\n",
    "    output_text_file = video_file.split('.')[0] + '_transcription.txt'\n",
    "    with open(output_text_file, 'w') as f:\n",
    "        f.write(transcription)\n",
    "    \n",
    "    print(f\"Transcription for {video_file} saved to {output_text_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalizing the text\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to perform any text normalization steps that are necessary for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-07T16:53:19.413643Z",
     "start_time": "2024-04-07T16:53:17.705657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sandy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sandy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sandy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text in Mod01_Course_Overview_transcription.txt normalized.\n",
      "Text in Mod02_Intro_transcription.txt normalized.\n",
      "Text in Mod02_Sect01_transcription.txt normalized.\n",
      "Text in Mod02_Sect02_transcription.txt normalized.\n",
      "Text in Mod02_Sect03_transcription.txt normalized.\n",
      "Text in Mod02_Sect04_transcription.txt normalized.\n",
      "Text in Mod02_Sect05_transcription.txt normalized.\n",
      "Text in Mod02_WrapUp_transcription.txt normalized.\n",
      "Text in Mod03_Intro_transcription.txt normalized.\n",
      "Text in Mod03_Sect01_transcription.txt normalized.\n",
      "Text in Mod03_Sect02_part1_transcription.txt normalized.\n",
      "Text in Mod03_Sect02_part2_transcription.txt normalized.\n",
      "Text in Mod03_Sect02_part3_transcription.txt normalized.\n",
      "Text in Mod03_Sect03_part1_transcription.txt normalized.\n",
      "Text in Mod03_Sect03_part2_transcription.txt normalized.\n",
      "Text in Mod03_Sect03_part3_transcription.txt normalized.\n",
      "Text in Mod03_Sect04_part1_transcription.txt normalized.\n",
      "Text in Mod03_Sect04_part2_transcription.txt normalized.\n",
      "Text in Mod03_Sect04_part3_transcription.txt normalized.\n",
      "Text in Mod03_Sect05_transcription.txt normalized.\n",
      "Text in Mod03_Sect06_transcription.txt normalized.\n",
      "Text in Mod03_Sect07_part1_transcription.txt normalized.\n",
      "Text in Mod03_Sect07_part2_transcription.txt normalized.\n",
      "Text in Mod03_Sect07_part3_transcription.txt normalized.\n",
      "Text in Mod03_Sect08_transcription.txt normalized.\n",
      "Text in Mod03_WrapUp_transcription.txt normalized.\n",
      "Text in Mod04_Intro_transcription.txt normalized.\n",
      "Text in Mod04_Sect01_transcription.txt normalized.\n",
      "Text in Mod04_Sect02_part1_transcription.txt normalized.\n",
      "Text in Mod04_Sect02_part2_transcription.txt normalized.\n",
      "Text in Mod04_Sect02_part3_transcription.txt normalized.\n",
      "Text in Mod04_WrapUp_transcription.txt normalized.\n",
      "Text in Mod05_Intro_transcription.txt normalized.\n",
      "Text in Mod05_Sect01_ver2_transcription.txt normalized.\n",
      "Text in Mod05_Sect02_part1_ver2_transcription.txt normalized.\n",
      "Text in Mod05_Sect02_part2_transcription.txt normalized.\n",
      "Text in Mod05_Sect03_part1_transcription.txt normalized.\n",
      "Text in Mod05_Sect03_part2_transcription.txt normalized.\n",
      "Text in Mod05_Sect03_part3_transcription.txt normalized.\n",
      "Text in Mod05_Sect03_part4_ver2_transcription.txt normalized.\n",
      "Text in Mod05_WrapUp_ver2_transcription.txt normalized.\n",
      "Text in Mod06_Intro_transcription.txt normalized.\n",
      "Text in Mod06_Sect01_transcription.txt normalized.\n",
      "Text in Mod06_Sect02_transcription.txt normalized.\n",
      "Text in Mod06_WrapUp_transcription.txt normalized.\n",
      "Text in Mod07_Sect01_transcription.txt normalized.\n"
     ]
    }
   ],
   "source": [
    "# Write your answer/code here\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize NLTK components\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define synonyms and abbreviations mapping\n",
    "synonym_map = {\n",
    "    'u': 'you',\n",
    "    'r': 'are',\n",
    "    '\\'ur': 'your',\n",
    "    '\\'ll': 'will',\n",
    "    'can\\'t': 'cannot',\n",
    "    'don\\'t': 'do not',\n",
    "    'won\\'t': 'will not',\n",
    "    'i\\'m': 'i am',\n",
    "    'i\\'ve': 'i have',\n",
    "    'i\\'d': 'i would',\n",
    "    'isn\\'t': 'is not',\n",
    "    'wasn\\'t': 'was not',\n",
    "    'weren\\'t': 'were not',\n",
    "    'haven\\'t': 'have not',\n",
    "    'hasn\\'t': 'has not',\n",
    "    'hadn\\'t': 'had not',\n",
    "    'doesn\\'t': 'does not',\n",
    "    'didn\\'t': 'did not',\n",
    "    'couldn\\'t': 'could not',\n",
    "    'wouldn\\'t': 'would not',\n",
    "    'mightn\\'t': 'might not',\n",
    "    'mustn\\'t': 'must not',\n",
    "    'shan\\'t': 'shall not',\n",
    "    'shan\\'t\\'ve': 'shall not have',\n",
    "    'should\\'ve': 'should have',\n",
    "    'shouldn\\'t': 'should not',\n",
    "    'shouldn\\'t\\'ve': 'should not have',\n",
    "    'so\\'ve': 'so have',\n",
    "    'so\\'s': 'so as',\n",
    "    'this\\'s': 'this is',\n",
    "    'that\\'s': 'that is',\n",
    "    'there\\'ve': 'there have',\n",
    "    'there\\'s': 'there is',\n",
    "    'here\\'s': 'here is',\n",
    "    'where\\'d': 'where did',\n",
    "    'where\\'s': 'where is',\n",
    "    'where\\'ve': 'where have',\n",
    "    'who\\'ve': 'who have',\n",
    "    'who\\'s': 'who is',\n",
    "    'who\\'d': 'who would',\n",
    "    'who\\'d\\'ve': 'who would have',\n",
    "    'why\\'s': 'why is',\n",
    "    'how\\'ve': 'how have',\n",
    "    'we\\'ll': 'we will',\n",
    "    'you\\'ll': 'you will',\n",
    "    'they\\'ll': 'they will',\n",
    "    'i\\'ll': 'i will',\n",
    "    'he\\'ll': 'he will',\n",
    "    'she\\'ll': 'she will',\n",
    "    'it\\'ll': 'it will',\n",
    "    'youll': 'you will',\n",
    "    'theyll': 'they will',\n",
    "    'ill': 'i will',\n",
    "    'hell': 'he will',\n",
    "    'shell': 'she will',\n",
    "    'itll': 'it will',\n",
    "    'youre': 'you are',\n",
    "    'theyre': 'they are',\n",
    "    'youve': 'you have',\n",
    "    'theyve': 'they have',\n",
    "    'weve': 'we have',\n",
    "    'ive': 'i have',\n",
    "    'hes': 'he is',\n",
    "    'shes': 'she is',\n",
    "    'its': 'it is',\n",
    "    'thats': 'that is',\n",
    "    'whos': 'who is',\n",
    "    'thatll': 'that will',\n",
    "    'whichll': 'which will',\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "# Function for text normalization\n",
    "def normalize_text(text):\n",
    "    # 1. Case Normalization\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Punctuation Removal, Removing numbers and symbol\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # 3. Stop Word Removal, Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # 4. Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # 5. Replacing synonyms and Abbreviation\n",
    "    text = ' '.join(tokens)\n",
    "    text = replace_synonyms_abbreviations(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Function to replace synonyms and abbreviations\n",
    "def replace_synonyms_abbreviations(text):\n",
    "    # Replace synonyms and abbreviations\n",
    "    for word in text.split():\n",
    "        if word in synonym_map:\n",
    "            text = text.replace(word, synonym_map[word])\n",
    "\n",
    "    return text\n",
    "\n",
    "# Get all text files in the current directory\n",
    "text_files = [f for f in os.listdir() if f.endswith('_transcription.txt')]\n",
    "\n",
    "# Normalize text in each file\n",
    "for text_file in text_files:\n",
    "    with open(text_file, 'r') as f:\n",
    "        transcription = f.read()\n",
    "        normalized_transcription = normalize_text(transcription)\n",
    "    \n",
    "    # Write normalized transcription back to the file\n",
    "    with open(text_file, 'w') as f:\n",
    "        f.write(normalized_transcription)\n",
    "\n",
    "    print(f\"Text in {text_file} normalized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting key phrases and topics\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to extract the key phrases and topics from the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-07T16:53:46.472525Z",
     "start_time": "2024-04-07T16:53:19.413736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested videos based on 'machine learning' topic or keyword:\n",
      "Mod01_Course_Overview.mp4\n",
      "Mod02_Intro.mp4\n",
      "Mod02_Sect02.mp4\n",
      "Mod02_Sect03.mp4\n",
      "Mod02_Sect04.mp4\n",
      "Mod02_WrapUp.mp4\n",
      "Mod03_Sect02_part1.mp4\n"
     ]
    }
   ],
   "source": [
    "#Write your answer/code here\n",
    "\n",
    "from bertopic import BERTopic\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Function to extract topics and key phrases from a single text file\n",
    "def extract_topics_and_keyphrases(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Assuming you have already downloaded and loaded a spaCy model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extracting key phrases\n",
    "    key_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "\n",
    "    return text, key_phrases\n",
    "\n",
    "# Function to process all text files in the current directory\n",
    "def process_text_files():\n",
    "    # Get all files ending with \"_transcription.txt\" in the current directory\n",
    "    files = [f for f in os.listdir('.') if f.endswith('_transcription.txt')]\n",
    "\n",
    "    topics_and_keyphrases = defaultdict(list)\n",
    "\n",
    "    for file in files:\n",
    "        text, key_phrases = extract_topics_and_keyphrases(file)\n",
    "        topics_and_keyphrases[file] = (text, key_phrases)\n",
    "\n",
    "    return topics_and_keyphrases\n",
    "\n",
    "# Function to suggest videos based on input topic or keyword\n",
    "def suggest_videos(input_topic_or_keyword, topics_and_keyphrases):\n",
    "    # Perform topic modeling using BERTopic\n",
    "    texts = [text for text, _ in topics_and_keyphrases.values()]\n",
    "    model = BERTopic(language=\"english\")\n",
    "    topics, _ = model.fit_transform(texts)\n",
    "\n",
    "    # Get the topic or keyword related files\n",
    "    related_files = []\n",
    "    for file, (_, key_phrases) in topics_and_keyphrases.items():\n",
    "        if input_topic_or_keyword in key_phrases:\n",
    "            related_files.append(file)\n",
    "\n",
    "    # Extract video names from transcript file names\n",
    "    video_names = [file.split('_transcription.txt')[0] for file in related_files]\n",
    "\n",
    "    # Search for corresponding video files in the directory\n",
    "    video_files = [file + '.mp4' for file in video_names if os.path.isfile(file + '.mp4')]\n",
    "\n",
    "    return video_files\n",
    "\n",
    "# Process text files in the current directory\n",
    "topics_and_keyphrases = process_text_files()\n",
    "\n",
    "# Example of suggesting videos based on a topic or keyword\n",
    "input_topic_or_keyword = \"machine learning\"\n",
    "suggested_videos = suggest_videos(input_topic_or_keyword, topics_and_keyphrases)\n",
    "print(\"Suggested videos based on '{}' topic or keyword:\".format(input_topic_or_keyword))\n",
    "for video in suggested_videos:\n",
    "    print(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the dashboard\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to create the dashboard for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-04-07T17:24:47.140242Z",
     "start_time": "2024-04-07T17:24:33.215553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x1923df673d0>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"650\"\n            src=\"http://127.0.0.1:8050/\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your answer/code here\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import os\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Process text files in the current directory\n",
    "topics_and_keyphrases = process_text_files()\n",
    "\n",
    "# Define CSS styles\n",
    "styles = {\n",
    "    'input': {'margin': '10px', 'width': '300px', 'height': '30px', 'font-size': '16px'},\n",
    "    'button': {'margin': '10px', 'width': '100px', 'height': '40px', 'font-size': '16px', 'background-color': '#4CAF50', 'color': 'white', 'border': 'none', 'cursor': 'pointer'},\n",
    "    'output': {'margin': '10px', 'font-size': '16px'}\n",
    "}\n",
    "\n",
    "# Create Dash layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Video Suggestion Dashboard\", style={'text-align': 'center'}),\n",
    "    dcc.Input(id='input-topic', type='text', placeholder='Enter topic or keyword', style=styles['input']),\n",
    "    html.Button('Submit', id='submit-val', n_clicks=0, style=styles['button']),\n",
    "    html.Div(id='output-videos', style=styles['output'])\n",
    "])\n",
    "\n",
    "# Callback to suggest videos based on input topic or keyword\n",
    "@app.callback(\n",
    "    Output('output-videos', 'children'),\n",
    "    [Input('submit-val', 'n_clicks')],\n",
    "    [dash.dependencies.State('input-topic', 'value')]\n",
    ")\n",
    "def update_output(n_clicks, input_topic):\n",
    "    if input_topic is None:\n",
    "        return html.Div(\"Please enter a topic or keyword\", style=styles['output'])\n",
    "    else:\n",
    "        suggested_videos = suggest_videos(input_topic, topics_and_keyphrases)\n",
    "        if not suggested_videos:\n",
    "            return html.Div(\"No videos found for the given topic or keyword\", style=styles['output'])\n",
    "        else:\n",
    "            return html.Div([html.P(video) for video in suggested_videos], style=styles['output'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
